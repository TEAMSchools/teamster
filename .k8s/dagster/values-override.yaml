########################################################################################
# Dagster Cloud: Config for Dagster Cloud's hosted resources
########################################################################################
dagsterCloud:
  # Specify the Dagster Cloud deployments (e.g. dev, staging, prod) that the agent
  # should serve.
  deployments:
    - prod

  # Specify whether the agent should also serve branch deployments for your
  # organization.
  branchDeployments: true

  # # Optionally customize the socket_options that are passed in to the underlying HTTP
  # # connection pool used to send HTTP requests to Dagster Cloud.
  # socketOptions:
  #   - [SOL_SOCKET, SO_KEEPALIVE, 1]
  #   - [IPPROTO_TCP, TCPKEEPIDLE, 11]
  #   - [IPPROTO_TCP, TCPKEEPINTVL, 7]
  #   - [IPPROTO_TCP, TCPKEEPCNT, 5]

  # # Optionally specify the timeout in seconds to use when making requests to Dagster
  # # Cloud servers.
  # timeout: 4

  # # Optionally specify the number of retries to use when an HTTPS request to Dagster Cloud servers
  # # fails with a retryable error.
  # retries: 15

########################################################################################
# Dagster Cloud Agent: Configuration for the Dagster Cloud (User) Agent
########################################################################################
dagsterCloudAgent:
  resources:
    requests:
      cpu: 750m
      memory: 1.5Gi
    limits:
      cpu: 750m
      memory: 1.5Gi
  nodeSelector:
    cloud.google.com/gke-placement-group: servers
    cloud.google.com/compute-class: Balanced
    cloud.google.com/gke-spot: "true"

########################################################################################
# Workspace: Configuration for pods (launched by the agent) that run Dagster user code
########################################################################################
workspace:
  # Raw k8s configuration for the Kubernetes Job and Pod created for each run. See:
  # https://docs.dagster.io/deployment/guides/kubernetes/customizing-your-deployment
  runK8sConfig:
    podTemplateSpecMetadata: # raw config for the pod's metadata
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
    podSpecConfig:
      nodeSelector:
        cloud.google.com/compute-class: Scale-Out
        kubernetes.io/arch: arm64

  # Raw k8s configuration for the Kubernetes Deployment created for each code location.
  serverK8sConfig:
    podTemplateSpecMetadata: # raw config for the pod's metadata
      annotations:
        operator.1password.io/auto-restart: "true"
    podSpecConfig:
      nodeSelector:
        cloud.google.com/gke-spot: "true"
        cloud.google.com/compute-class: Balanced
        cloud.google.com/gke-placement-group: servers
      terminationGracePeriodSeconds: 25

  # Specify TTL for user code servers.
  # By default full deployment servers do not have a TTL.
  # Branch deployments servers have a default TTL of 24 hours
  # The max code servers defaults to 25, and only applies to servers with TTL.
  serverTTL:
    branchDeployments:
      ttlSeconds: 300

########################################################################################
# Extra Manifests: (Optional) Create additional k8s resources within this chart
########################################################################################
extraManifests:
  # Useful for providing extra configuration -- e.g. RBAC/serviceAccount information,
  # etc. -- for user workspace pods.
  - apiVersion: policy/v1
    kind: PodDisruptionBudget
    metadata:
      name: pdb-agent
    spec:
      maxUnavailable: 0
      selector:
        matchLabels:
          component: agent
  - apiVersion: policy/v1
    kind: PodDisruptionBudget
    metadata:
      name: pdb-kippcamden
    spec:
      maxUnavailable: 0
      selector:
        matchLabels:
          location_name: kippcamden
  - apiVersion: policy/v1
    kind: PodDisruptionBudget
    metadata:
      name: pdb-kippmiami
    spec:
      maxUnavailable: 0
      selector:
        matchLabels:
          location_name: kippmiami
  - apiVersion: policy/v1
    kind: PodDisruptionBudget
    metadata:
      name: pdb-kippnewark
    spec:
      maxUnavailable: 0
      selector:
        matchLabels:
          location_name: kippnewark
