# README:
# - If using a fixed tag for images, changing the image pull policy to anything other than "Always"
#   will use a cached/stale image.
---
# Specify secrets to run containers based on images in private registries. See:
# https://kubernetes.io/docs/concepts/containers/images/#referring-to-an-imagepullsecrets-on-a-pod
imagePullSecrets: []

serviceAccount:
  # Specifies whether a service account is created for the Dagster Cloud agent.
  #
  # If false, you must ensure the service account has the correct permissions for the agent.
  create: true

  # Specifies the name for service account for the Dagster Cloud agent.
  #
  # By default, this name is autogenerated.
  name: ""

  annotations: {}

####################################################################################################
# Dagster Cloud: Config for Dagster Cloud's hosted resources
####################################################################################################
dagsterCloud:
  # Specify the name of the secret containing a Dagster Cloud agent token. This secret will be
  # automatically referenced in the agent pod and any pods that the agent creates to run Dagster
  # code, ensuring that all pods can authenticate with Dagster Cloud servers. The Helm chart
  # expects this secret to already exist when it is installed.
  agentTokenSecretName: "dagster-cloud-agent-token"

  # You can also set agentTokenValue to the value of a Dagster Cloud agent token instead of using
  # agentTokenSecretName for authentication. However, if this value is set, the agent token's will
  # be visible in plaintext in the description of the agent pod, as well as other pods that it creates.
  # This is primarily useful if the agent is creating pods in multiple namespaces and you don't
  # want to have to add the secret containing the agent token to each namespace.
  # agentTokenValue: "your-agent-token-value-here"

  # Specify the Dagster Cloud deployments (e.g. dev, staging, prod) that the agent should serve.
  # Example:
  #
  # deployments:
  #   - prod
  deployments: ~

  # Specify whether the agent should also serve branch deployments for your organization.
  branchDeployments: false

  # Specify your organization's Dagster Cloud endpoint.
  #
  # By default, this will be "https://<organization_name>.agent.dagster.cloud".
  # Your organization name will automatically be determined using your API token.
  endpoint: ~

  # An optional label which will identify the agent on the status page.
  agentLabel: ~

  # Optionally specify the timeout in seconds to use when making requests to Dagster Cloud servers.
  # timeout: 60

  # Optionally specify the number of retries to use when an HTTPS request to Dagster Cloud servers
  # fails with a retryable error.
  # retries: 6

  # Optionally specify the exponential backoff factor to use when an HTTP request to Dagster Cloud
  # servers fails with a retryable error.
  # backoffFactor: 0.5

  # Optionally configure the agent process requests for code locations annotated with a specific agent queue.
  # Examples:
  #
  # To only process requests for code locations annotated with "foo"
  #
  # agentQueues:
  #   includeDefaultQueue: false
  #   additionalQueues:
  #     - foo
  #
  # To process requests for code locations annotated with "foo" and any location that isn't annotated with an agent queue:
  #
  # agentQueues:
  #   includeDefaultQueue: true
  #   additionalQueues:
  #     - foo

####################################################################################################
# Dagster Cloud Agent: Configuration for the Dagster Cloud (User) Agent
####################################################################################################
dagsterCloudAgent:
  image:
    repository: "docker.io/dagster/dagster-cloud-agent"
    # When a tag field is specified as nil, it will default as the Helm chart version
    tag: ~
    pullPolicy: "Always"

  # initContainers are used for testing, since the host cloud will not be available while it is starting
  initContainers: []

  # # When the agent has completed its first reconciliation loop, it writes an empty
  # # sentinel file. We can check for the completion of this first reconciliation loop
  # # (which means all code servers are running) by checking for the existence of this file.
  # # When attempting zero downtime agent updates, this readiness probe should be set.
  # readinessProbe:
  #   exec:
  #     command:
  #       - /bin/bash
  #       - -c
  #       - test -f /tmp/finished_initial_reconciliation_sentinel.txt
  #   failureThreshold: 60
  #   initialDelaySeconds: 0
  #   periodSeconds: 10

  # # Set the type of update strategy to use. The default settings provided here will
  # # ensure that updates happen with zero downtime.
  # deploymentStrategy:
  #   type: "RollingUpdate"
  #   rollingUpdate:
  #     maxUnavailable: 0%
  #     maxSurge: 200%

  # Additional environment variables to set.
  # A Kubernetes ConfigMap will be created with these environment variables. See:
  # https://kubernetes.io/docs/concepts/configuration/configmap/
  #
  # Example:
  #
  # env:
  #   ENV_ONE: one
  #   ENV_TWO: two
  env: {}

  # Additional sources of environment variables on the agent container. Follows the
  # same format as the `envFrom` dictionary in a Kubernes pod container. Note that this
  # configuration will not automatically be included in other pods that the agent
  # creates - see the `workspace` section below to specify environment variables in those
  # pods.
  envFrom: []

  annotations: {}
  labels: {}
  nodeSelector: {}
  affinity: {}
  tolerations: []

  # Override the default K8s scheduler
  # schedulerName: ~

  # Security context for the agent pod.
  # https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  #
  # To run the agent as a non-root user, use the following config. This will be enabled by default in a
  # future release.
  #
  # podSecurityContext:
  #   runAsUser: 1001 # provided non-root user in image versions 0.14.0 and above
  podSecurityContext: {}

  # Security context for the agent container.
  securityContext: {}

  resources: {}

  # Override the Python logging config for the logs produced by the agent system pod. (Use
  # `pythonLogs` below to change the logging config for pods running user code). The format of this
  # dictionary follows the same format that can be passed into logging.config.dictConfig
  # (https://docs.python.org/3/library/logging.config.html#logging.config.dictConfig)
  loggingConfig: {}

  # Number of replicas of the agent service to keep up at a given time.
  replicas: 1

  # Additional volumes for the agent pod and volumeMounts for the container.
  # volumes:
  # volumeMounts:

####################################################################################################
# Workspace: Configuration for pods (launched by the agent) that run Dagster user code
####################################################################################################
workspace:
  # Specifies the pull policy for the code servers launched by the agent
  pullPolicy: "Always"

  # Specifies the service account that the code servers will use.
  #
  # If set, you must provide the named service account and role bindings yourself.
  # You can optionally do so in the `extraManifests` field.
  serviceAccountName: ~

  # Specifies the namespace in which the agent launches the code servers. By default,
  # this will be the Helm release namespace.
  namespace: ~

  # Additional environment variables can be retrieved and set from Secrets. See:
  # https://kubernetes.io/docs/concepts/configuration/secret/#use-case-as-container-environment-variables
  #
  # Example:
  #
  # envSecrets:
  #   - name: secret
  #     optional: true
  envSecrets: []

  # Additional variables from the existing environment can be passed into any launched pods.
  #
  # Example:
  #
  # envVars:
  #   - "FOO_ENV_VAR" (Will pull the value of FOO_ENV_VAR from the agent process)
  #   - "BAR_ENV_VAR=baz_value" (Will set the value of BAR_ENV_VAR to baz_value)
  envVars: []

  # Additional environment variables can be retrieved and set from ConfigMaps. See:
  # https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-container-environment-variables
  #
  # Example:
  #
  # envConfigMaps:
  #   - name: config-map
  envConfigMaps: []

  # Additional volumes that should be included in any Pods created by the agent. See:
  # https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volume-v1-core
  #
  # Example:
  #
  # volumes:
  #   - name: my-volume
  #     configMap: my-config-map
  volumes: []

  # Additional volume mounts that should be included in the container in any Pods created by the agent. See:
  # See: https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volumemount-v1-core
  #
  # Example:
  #
  # volumeMounts:
  #   - name: test-volume
  #     mountPath: /opt/dagster/test_folder
  #     subPath: test_file.yaml
  volumeMounts: []

  # Additional labels that should be included in the pods created by the agent. See:
  # https://kubernetes.io/docs/concepts/overview/working-with-objects/labels
  #
  # Example:
  # labels:
  #   my_label_key: my_label_value
  labels: {}

  # Default compute resource requirements for the pods created by the agent. See:
  # https://kubernetes.io/docs/concepts/configuration/manage-resources-containers
  #
  # Example:
  # resources:
  #   limits:
  #     cpu: 100m
  #     memory: 128Mi
  #   requests:
  #     cpu: 100m
  #     memory: 128Mi
  resources: {}


  # Specifies the timeout when creating a new Kubernetes deployment for a code server.
  #
  # If not set, defaults to 300 seconds.
  deploymentStartupTimeout: ~

  # Specifies an amount of time that the agent will wait for an image to fail to pull
  # when spinning up a new deployment before it will consider the image to be invalid and mark
  # it as failed. Can be used in cases where a new image has been pushed but caching issues
  # prevent the image from being able to be pulled right away.
  #
  # If not set, defaults to 30 seconds.
  imagePullGracePeriod: ~

  # Specifies the timeout in seconds the agent should use when waiting for a code server to be
  # ready after the Kubernetes deployment is created. If not set, defaults to 180 seconds.
  #
  # This timeout should be increased if your code locations can take more than 3 minutes to load
  # your Dagster definitions.
  serverProcessStartupTimeout: ~

  # Override the default K8s scheduler
  # schedulerName: ~

  # Specify TTL for user code servers.
  # By default full deployment servers do not have a TTL.
  # Branch deployments servers have a default TTL of 24 hours
  # The max code servers defaults to 25, and only applies to servers with TTL.
  #
  # Example:
  # serverTTL:
  #   fullDeployments:
  #     enabled: true
  #     ttlSeconds: 7200 # 2 hours
  #   branchDeployments:
  #     ttlSeconds: 3600 # 1 hours
  #   maxServers: 10
  serverTTL: ~

  # Controls how workspace snapshots are uploaded.
  # The default enabled behavior is to upload job snapshots separately, only if they have not
  # been uploaded before. When disabled, the workspace snapshot is uploaded as a single payload.
  deferJobSnapshots: ~

  # Specifies security settings for pods launched by the agent.
  securityContext: ~

  # Raw k8s configuration for the Kubernetes Job and Pod created for each run.
  # See: https://docs.dagster.io/deployment/guides/kubernetes/customizing-your-deployment
  #
  # Example:
  # runK8sConfig:
  #   containerConfig: # raw config for the pod's main container
  #     resources:
  #       cpu: 100m
  #       memory: 128Mi
  #   podTemplateSpecMetadata: # raw config for the pod's metadata
  #     annotations:
  #       mykey: myvalue
  #   podSpecConfig: # raw config for the spec of the launched's pod
  #     nodeSelector:
  #       disktype: ssd
  #   jobSpecConfig: # raw config for the kubernetes job's spec
  #     ttlSecondsAfterFinished: 7200
  #   jobMetadata: # raw config for the kubernetes job's metadata
  #     annotations:
  #       mykey: myvalue
  runK8sConfig: {}

  # Raw k8s configuration for the Kubernetes Deployment created for each code location.
  #
  # Example:
  # serverK8sConfig:
  #   containerConfig: # raw config for the pod's main container
  #     resources:
  #       cpu: 100m
  #       memory: 128Mi
  #   podTemplateSpecMetadata: # raw config for the pod's metadata
  #     annotations:
  #       mykey: myvalue
  #   podSpecConfig: # raw config for the spec of the launched's pod
  #     nodeSelector:
  #       disktype: ssd
  serverK8sConfig: {}

####################################################################################################
# Compute Logs: (Optional) settings for compute logging
####################################################################################################
computeLogs:
  # Specifies if compute logs will be forwarded to dagster cloud
  enabled: true

  # For custom configuration of compute log manager, Example:
  # custom:
  #   module: dagster_cloud
  #   class: CloudComputeLogManager
  #   config:
  #     upload_interval: 60


####################################################################################################
# Python Logs (Optional) settings for configuring Python logging behavior in your jobs.
####################################################################################################
# Example:
# pythonLogs:
#   # The names of python loggers that will be captured as Dagster logs
#   managedPythonLoggers:
#     - foo_logger
#   # The log level for the instance. Logs emitted below this severity will be ignored.
#   # One of [NOTSET, DEBUG, INFO, WARNING, WARN, ERROR, FATAL, CRITICAL]
#   pythonLogLevel: INFO
#   # Python log handlers that will be applied to all Dagster logs
#   dagsterHandlerConfig:
#     handlers:
#       myHandler:
#         class: logging.FileHandler
#         filename: "/logs/my_dagster_logs.log"
#         mode: "a"
pythonLogs: {}

####################################################################################################
# Isolated Agents: (Optional, Experimental) When running multiple agents for the same
# Dagster Cloud deployment, set this flag to true if the agents are running in
# environments that do not have access to each others resources (for example, if they
# are running in different Kubernetes clusters or in different namespaces within the
# same cluster). Setting this flag to true ensures that features like run termination
# will still work correctly.
####################################################################################################
isolatedAgents:
  enabled: false

####################################################################################################
# Extra Manifests: (Optional) Create additional k8s resources within this chart
####################################################################################################
extraManifests:
# Useful for providing extra configuration -- e.g. RBAC/serviceAccount information, etc. --
# for user workspace pods.
#  # You can also set default container resource requests/limits for the namespace
#  #   * To override these for dagster system containers; edit the resources sections of
#  #     this values yaml -  eg: dagsterCloudAgent.resources
#  - apiVersion: v1
#    kind: LimitRange
#    metadata:
#      name: default-container-resources
#    spec:
#      limits:
#        - default:
#            cpu: 250m
#            memory: 512Mi
#          defaultRequest:
#            cpu: 100m
#            memory: 256Mi
#          type: Container
#  # Example 2:
#  - apiVersion: cloud.google.com/v1beta1
#    kind: BackendConfig
#    metadata:
#      name: "{{ .Release.Name }}-backend-config"
#      labels:
#      {{- include "dagster.labels" . | nindent 6 }}
#      spec:
#        securityPolicy:
#          name: "gcp-cloud-armor-policy-test"

